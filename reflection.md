As our group coded the five different methods of controlling the game,
we observed many different things about each method. In particular, we noticed which things worked well and which things did not. 

For the first function, mapping different keys to directions, we found that it was very intuitive and familiar to use these controls. The performance of this gesture was very effective. This is due in part by the fact using keys similar to the arrow keys is very ingrained in our modern motor functions. The feedback and tactile nature of the buttons also reinforce the visibility of this gesture. 

For the second gesture using the trackpad we found that it also aligned very well with the modern college students capability. Many students use their trackpad very consistently through the day; thus, the risk of the movement is fairly low since our comfort levels and trust in a trackpad are so high. However, we did note that the performance of the trackpad was second to that of the buttons due to the fact dragging a finger across the trackpad takes somehwat longer than pressing a single button. 

After implementing the color tracking function, we discovered several different things. First, the responsiveness was not nearly on par with that of the buttons or trackpad. Although the function does a quality job of tracking the color, the performance is seriously decreased. The coordination and tactility of moving a colored object through space certainly increases visibility of the gesture. However, one major point to note is the fact that moving an object through 3D space in front of a computer is a gesture not many are accustomed to. For this reason, the trust in the control is somewhat lost and the thickness of practice is increased. Commonly we use mouses and keys to control computer, so this new method may seem awkward for seom people. 

The fourth control of finger tracking shared many of the same observations with the color tracker. Its practicality was questionable since we are not used to changing the number of fingers we hold up in order to control direction. One thing that was very successful with this approach was the visibility and performance. The fact that the gesture is an extension of human movement makes it very accessible and natural in use. The visual feedback given by the camera overlay is also very helpful in learning to use it. Risk was also diminished in comparison to the color tracker since most, but not all, have very good awareness of their own hands. 

Lastly, our unique function combined several of the familiar aspects from the buttons and trackpad. We had decided to create a function that used scrolling along with right and left click to dictate direction. This came with several advantages and limitations. The function itslef is made with the idea that you are using a mouse in order to control it. For that reason, it is a somewhat of a limiting factor. However, when used with a mouse, the gestures are very intuitive and familiar with ample visual feedback since the mouse is in contact with the user. Another major limitation stem from the operating system in which you use the function on. For Mac OS, the default settings for the right click opens a menu dropdown regardless of where you click. While the game control still functioned correctly, the constant menus obstructed the view of the game. This becomes a major blockage in the performance of the control. Beyond that, the mouse function operated very similarly to the first and second implementations of trackpad and button related controls. 